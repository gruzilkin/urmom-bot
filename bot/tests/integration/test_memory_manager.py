"""
Integration tests for MemoryManager with real AI clients and realistic physics data.
These tests use actual Gemini/Gemma (and optionally Ollama Kimi) APIs and the full physics chat history.
"""

import os
import time
import unittest
from dataclasses import dataclass
from datetime import date
from unittest.mock import AsyncMock

from dotenv import load_dotenv

from memory_manager import MemoryManager
from null_telemetry import NullTelemetry
from gemini_client import GeminiClient
from gemma_client import GemmaClient
from ollama_client import OllamaClient
from test_store import TestStore

# Load environment variables from .env file
load_dotenv()


@dataclass(frozen=True)
class MergeProfile:
    """Describes a merge-capable AI client used by MemoryManager."""

    name: str
    client: object


@dataclass
class MemoryTestContext:
    """Encapsulates per-profile MemoryManager state."""

    memory_manager: MemoryManager
    store: TestStore

 
class MemoryManagerTestBase(unittest.IsolatedAsyncioTestCase):
    """Shared setup utilities for MemoryManager integration tests."""

    def setUp(self):
        self.telemetry = NullTelemetry()
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.gemini_model = os.getenv("GEMINI_FLASH_MODEL")
        if not self.api_key:
            self.skipTest("GEMINI_API_KEY environment variable not set")
        if not self.gemini_model:
            self.skipTest("GEMINI_FLASH_MODEL environment variable not set")

        self.gemini_client = GeminiClient(
            api_key=self.api_key,
            model_name=self.gemini_model,
            telemetry=self.telemetry,
            temperature=0.1,
        )

        self.merge_profiles: list[MergeProfile] = []

        gemma_model = os.getenv("GEMINI_GEMMA_MODEL")
        if gemma_model:
            gemma_client = GemmaClient(
                api_key=self.api_key,
                model_name=gemma_model,
                telemetry=self.telemetry,
                temperature=0.1,
            )
            self.merge_profiles.append(MergeProfile(name="gemma", client=gemma_client))

        ollama_api_key = os.getenv("OLLAMA_API_KEY")
        if ollama_api_key:
            kimi_model = os.getenv("OLLAMA_KIMI_MODEL", "kimi-k2:1t-cloud")
            kimi_client = OllamaClient(
                api_key=ollama_api_key,
                model_name=kimi_model,
                telemetry=self.telemetry,
                temperature=0.0,
            )
            self.merge_profiles.append(
                MergeProfile(name="ollama_kimi", client=kimi_client)
            )

        if not self.merge_profiles:
            self.skipTest(
                "No merge-capable AI clients configured (Gemma or Kimi required)."
            )

    def _build_context(self, profile: MergeProfile) -> MemoryTestContext:
        store = TestStore()
        memory_manager = MemoryManager(
            telemetry=self.telemetry,
            store=store,
            gemini_client=self.gemini_client,
            gemma_client=profile.client,
            user_resolver=store.user_resolver,
        )
        return MemoryTestContext(
            memory_manager=memory_manager,
            store=store,
        )


class TestMemoryManagerIntegration(MemoryManagerTestBase):
    """Integration tests for MemoryManager with realistic physics chat history and real AI."""

    async def test_realistic_batch_processing_monday(self):
        """Integration test: Process actual Monday physics discussions with real AI."""
        test_date = date(1905, 3, 3)

        # Daily summaries are generated by Gemini Flash only; run once without profile loop.
        ctx = self._build_context(self.merge_profiles[0])
        result = await ctx.memory_manager._create_daily_summaries(
            ctx.store.physics_guild_id, test_date
        )

        self.assertGreater(
            len(result), 0, "Should generate summaries for active physicists"
        )

        einstein_id = ctx.store.physicist_ids["Einstein"]
        self.assertIn(
            einstein_id, result, "Einstein should have a summary for Monday"
        )

        einstein_summary = result[einstein_id].lower()
        physics_terms = [
            "photoelectric",
            "quantum",
            "light",
            "energy",
            "wave",
            "particle",
        ]
        self.assertTrue(
            any(term in einstein_summary for term in physics_terms),
            f"Einstein's summary should contain physics terms. Got: {result[einstein_id]}",
        )

        expected_physicists = {"Einstein", "Planck", "Bohr", "Heisenberg"}
        actual_physicist_names = {
            name
            for name, user_id in ctx.store.physicist_ids.items()
            if user_id in result
        }
        overlap = expected_physicists.intersection(actual_physicist_names)
        self.assertGreaterEqual(
            len(overlap),
            3,
            f"Should include most key Monday physicists. Found: {actual_physicist_names}",
        )

    async def test_realistic_multi_day_merge_integration(self):
        """Integration test: Generate multi-day context merge spanning multiple days of real physics data."""
        facts = "Einstein is a theoretical physicist known for his work on relativity and quantum theory"
        daily_summaries = {
            date(1905, 3, 5): "Einstein discussed wave-particle duality and quantum mechanics",
            date(1905, 3, 4): "Einstein explored photoelectric effect implications",
            date(1905, 3, 3): "Einstein proposed quantum energy packets theory",
        }

        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                einstein_id = ctx.store.physicist_ids["Einstein"]
                result = await ctx.memory_manager._merge_context(
                    ctx.store.physics_guild_id, einstein_id, facts, daily_summaries
                )

                self.assertIsNotNone(
                    result, "Should generate multi-day context for Einstein"
                )
                self.assertGreater(
                    len(result), 50, "Multi-day context should be substantial"
                )

                result_lower = result.lower()
                einstein_themes = [
                    "einstein",
                    "quantum",
                    "relativity",
                    "determinism",
                    "physics",
                    "theory",
                ]
                themes_found = sum(1 for theme in einstein_themes if theme in result_lower)
                self.assertGreaterEqual(
                    themes_found,
                    3,
                    f"Multi-day context should reflect Einstein's themes. Got: {result}",
                )

    async def test_complete_memory_integration_with_facts_merge(self):
        """Integration test: Complete get_memories workflow with facts + current day + historical + AI merge."""
        einstein_facts = (
            "Einstein is a theoretical physicist known for developing the theory of relativity "
            "and quantum mechanics contributions"
        )

        from unittest.mock import patch
        from datetime import datetime, timezone

        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                einstein_id = ctx.store.physicist_ids["Einstein"]
                ctx.store.set_user_facts(
                    ctx.store.physics_guild_id, einstein_id, einstein_facts
                )

                with patch("memory_manager.datetime") as mock_datetime:
                    mock_datetime.now.return_value = datetime(
                        1905, 3, 6, 14, 30, tzinfo=timezone.utc
                    )
                    mock_datetime.side_effect = lambda *args, **kw: datetime(
                        *args, **kw
                    )

                    result = await ctx.memory_manager.get_memory(
                        ctx.store.physics_guild_id, einstein_id
                    )

                self.assertIsNotNone(result, "Should generate complete memory context")
                self.assertGreater(len(result), 100, "Complete memory should be substantial")

                result_lower = result.lower()

                fact_terms = ["einstein", "relativity", "physicist", "theory"]
                self.assertGreaterEqual(
                    sum(1 for term in fact_terms if term in result_lower),
                    2,
                    f"Should contain factual information. Got: {result}",
                )

                current_terms = ["matter", "wave", "nuclear", "quantum"]
                self.assertGreaterEqual(
                    sum(1 for term in current_terms if term in result_lower),
                    1,
                    f"Should contain current day themes. Got: {result}",
                )

                historical_terms = ["quantum", "determinism", "photoelectric"]
                self.assertGreaterEqual(
                    sum(1 for term in historical_terms if term in result_lower),
                    1,
                    f"Should contain historical patterns. Got: {result}",
                )

                self.assertNotIn(
                    "No factual information available",
                    result,
                    "Should have processed facts",
                )
                self.assertNotIn(
                    "No current day observations",
                    result,
                    "Should have processed current day",
                )
                self.assertNotIn(
                    "No historical observations",
                    result,
                    "Should have processed historical data",
                )


class TestMemoryManagerBatchIntegration(MemoryManagerTestBase):
    """Integration tests for batch processing with real AI clients."""

    async def test_batch_get_memories_multiple_physicists_real_ai(self):
        """Test batch processing of multiple physicists with real AI clients."""
        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                user_ids = [
                    ctx.store.physicist_ids["Einstein"],
                    ctx.store.physicist_ids["Bohr"],
                    ctx.store.physicist_ids["Planck"],
                ]

                results = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, user_ids
                )

                self.assertEqual(len(results), 3)
                for user_id in user_ids:
                    self.assertIn(user_id, results)
                    if results[user_id] is not None:
                        self.assertIsInstance(results[user_id], str)
                        self.assertGreater(
                            len(results[user_id]), 50
                        )  # Ensure a meaningful summary


class TestMemoryManagerLargeBatchIntegration(MemoryManagerTestBase):
    """Integration tests for large batch processing with real AI."""

    async def test_large_batch_scalability_all_physicists(self):
        """Test batch processing with all available physicists (5-10 users)."""
        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                all_user_ids = list(ctx.store.physicist_ids.values())

                results = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, all_user_ids
                )

                self.assertEqual(len(results), len(all_user_ids))
                for user_id in all_user_ids:
                    self.assertIn(user_id, results)
                    self.assertIsInstance(results[user_id], (str, type(None)))

    async def test_cache_effectiveness_with_real_ai_calls(self):
        """Test that caching reduces actual AI calls in real scenarios."""
        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                user_ids = [
                    ctx.store.physicist_ids["Einstein"],
                    ctx.store.physicist_ids["Bohr"],
                ]

                start_time_first = time.time()
                results1 = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, user_ids
                )
                duration_first = time.time() - start_time_first

                start_time_second = time.time()
                results2 = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, user_ids
                )
                duration_second = time.time() - start_time_second

                self.assertEqual(results1, results2)
                self.assertLess(
                    duration_second,
                    duration_first + 0.1,
                    "Cached call should be faster (allowing small jitter)",
                )

    async def test_memory_quality_consistency_batch_vs_individual(self):
        """Test that batch processing produces same quality as individual calls."""
        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                test_user_id = ctx.store.physicist_ids["Einstein"]

                individual_result = await ctx.memory_manager.get_memory(
                    ctx.store.physics_guild_id, test_user_id
                )
                batch_results = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, [test_user_id]
                )
                batch_result = batch_results.get(test_user_id)

                self.assertEqual(individual_result, batch_result)


class TestMemoryManagerRealExceptionHandling(MemoryManagerTestBase):
    """Test real exception handling with actual AI services."""

    async def test_graceful_degradation_with_facts_fallback(self):
        """Test that system falls back to facts when AI operations fail."""
        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                einstein_id = ctx.store.physicist_ids["Einstein"]
                facts = "Einstein is a theoretical physicist who developed relativity theory"
                ctx.store.set_user_facts(ctx.store.physics_guild_id, einstein_id, facts)

                ctx.memory_manager._gemini_client.generate_content = AsyncMock(
                    side_effect=Exception("AI quota exceeded")
                )
                ctx.memory_manager._gemma_client.generate_content = AsyncMock(
                    side_effect=Exception("AI quota exceeded")
                )

                result = await ctx.memory_manager.get_memory(
                    ctx.store.physics_guild_id, einstein_id
                )

                self.assertEqual(result, facts)

    async def test_partial_ai_failure_mixed_results(self):
        """Test behavior when some AI calls succeed and others fail."""
        from schemas import DailySummaries, UserSummary

        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                user_ids = [
                    ctx.store.physicist_ids["Einstein"],
                    ctx.store.physicist_ids["Bohr"],
                ]

                ctx.memory_manager._gemini_client.generate_content = AsyncMock(
                    return_value=DailySummaries(
                        summaries=[
                            UserSummary(user_id=uid, summary=f"Daily summary for {uid}")
                            for uid in user_ids
                        ]
                    )
                )
                ctx.memory_manager._gemma_client.generate_content = AsyncMock(
                    side_effect=Exception("Merge AI failed")
                )

                results = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, user_ids
                )

                self.assertEqual(len(results), 2)
                for user_id in user_ids:
                    self.assertIn(user_id, results)
                    if results[user_id] is not None:
                        self.assertIn("Daily summary", results[user_id])

    async def test_empty_response_handling(self):
        """Test handling of empty or malformed AI responses."""
        from schemas import DailySummaries

        for profile in self.merge_profiles:
            with self.subTest(profile=profile.name):
                ctx = self._build_context(profile)
                ctx.memory_manager._gemini_client.generate_content = AsyncMock(
                    return_value=DailySummaries(summaries=[])
                )

                user_ids = [ctx.store.physicist_ids["Einstein"]]
                results = await ctx.memory_manager.get_memories(
                    ctx.store.physics_guild_id, user_ids
                )

                self.assertEqual(len(results), 1)
                self.assertIn(ctx.store.physicist_ids["Einstein"], results)


if __name__ == '__main__':
    unittest.main()
